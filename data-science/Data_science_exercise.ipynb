{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagup Data Science Exercise\n",
    "\n",
    "ExampleCo, Inc is gathering several types of data for its fleet of very expensive machines.  These very expensive machines have three operating modes: *normal*, *faulty* and *failed*.   The machines run all the time, and usually they are in normal mode.  However, in the event that the machine enters faulty mode, the company would like to be aware of this as soon as possible.  This way they can take preventative action to avoid entering failed mode and hopefully save themselves lots of money.\n",
    "\n",
    "They collect four kinds of timeseries data for each machine in their fleet of very expensive machines.  When a machine is operating in *normal* mode the data behaves in a fairly predictable way, but with a moderate amount of noise.  Before a machine fails it will ramp into *faulty* mode, during which the data appears visibly quite different.  Finally, when a machine fails it enters a third, and distinctly different, *failed* mode where all signals are very close to 0.\n",
    "\n",
    "You can download the data here: [exampleco_data](https://drive.google.com/open?id=1b12u6rzkG1AxB6wLGl7IBVoaoSoZLHNR)\n",
    "\n",
    "## Objectives \n",
    "\n",
    "1. **Your primary objective is to develop an approach to detect the beginning of the “faulty” period**. Ideally, this approach would give the ExampleCo engineers as much time as possible to shut down their machines before failure occurs (at which time all measurements drop close to 0). The best solutions are automated in the sense that they would generalize to similar but slightly different data; simpler methods are acceptable but are less likely to receive full credit.\n",
    "2. Demonstrate the efficacy of your approach using visualizations. You must also include a simple explanation of these figures and why your approach is effective, ideally written in language that non-technical executives could understand.\n",
    "3. Finally, and now with a technical audience in mind, discuss the strengths and limitations of your approach and be sure to mention other approaches that you would have liked to try if you had more time.\n",
    "\n",
    "\n",
    "## Notes to help\n",
    "1. A good place to start is by addressing the noise due to communication\n",
    "   errors.\n",
    "2. Feel free to use any libraries you like. Your final results should be\n",
    "   presented in this Python notebook.\n",
    "3. There are no constraints on the techniques you bring to bear, we are curious\n",
    "   to see how you think and what sort of resources you have in your toolbox.\n",
    "4. **Be sure to clearly articulate what you did, why you did it, and how the\n",
    "   results should be interpreted**. In particular, you should be aware of the\n",
    "   limitations of whatever approach or approaches you take.\n",
    "5. Don't feel compelled to use all the data if you're not sure how. Feel free\n",
    "   to focus on data from a single unit if that makes it easier to get started.\n",
    "6. Don't hesitate to reach out to datasciencejobs@tagup.io with any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from ipywidgets import interact\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with an EDA of all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ed26d04d6e4c5b99a1bfd7f3e77501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data(machine=(0,19),percent=(2,100)):\n",
    "    \n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        \n",
    "        ax[i//2, i%2].plot(range(len(data)), data[str(i)])\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrolling through all the machines, we see that there are massive spikes due to the communications errors that mask out the signal. We need to remove these first. Since all the spikes occur over a value of 100, we can simply remove these values and replace them with a linear interpolation of the neighboring values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spikes(data):\n",
    "\n",
    "    cutoff = 100\n",
    "    data[abs(data)>cutoff] = np.nan\n",
    "    data = data.interpolate()\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ab2ea985374cd49d9e98d2493a5869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data(machine=(0,19),percent=(2,100)):\n",
    "    \n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        \n",
    "        ax[i//2, i%2].plot(range(len(data)), remove_spikes(data[str(i)]))\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot only around 2% of the data, we see that the signals from most sensors and machines are generally oscillatory, but there is also a high frequency component to the signals we might want to smooth over. Let's do this by simply taking a moving average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(data, window=10):\n",
    "    return data.rolling(window=window, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcca16a74bf4fb9aa1240fa6e6c07d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data(machine=(0,19),percent=(2,100)):\n",
    "    \n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "    clean_data = smooth_data(remove_spikes(data))\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "            \n",
    "        ax[i//2, i%2].plot(range(len(data)), clean_data[str(i)])\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better. <br />\n",
    "At this stage it's clear that there are 3 modes of operation: *normal, faulty*, and *failed*. <br /> \n",
    "These seem to be characterized as follows:\n",
    "* Normal mode: oscillatory with constant frequency and amplitude\n",
    "* Faulty mode: oscillatory, but with highly varying amplitude/frequency\n",
    "* Failed mode: near zero signal\n",
    "\n",
    "<br />\n",
    "Now, we need to build a model that can tell us the operating mode of the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approack 1: Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have labelled data, we need to use some form of unsupervised learning. <br />\n",
    "One option is to take batches of the data and see how they relate to each other. Given the nature of the data, we care about variations in frequency and aplitude over time. This suggests that a spectrogram would be a good representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34165fd032da4b1f96e604657c125cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_spectrogram(machine=(0, 19), percent=(2, 100), segment_size=[16, 32, 64, 128, 256]):\n",
    "\n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "    clean_data = smooth_data(remove_spikes(data))\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        f, t, Sxx = signal.spectrogram(clean_data[str(i)], nperseg=segment_size)\n",
    "\n",
    "        ax[i//2, i%2].pcolormesh(t, f, Sxx, shading='nearest', cmap=\"coolwarm\")\n",
    "        ax[i//2, i%2].set_ylabel('Frequency')\n",
    "        ax[i//2, i%2].set_xlabel('Time')\n",
    "        ax[i//2, i%2].set_xlim(0, t[-1]*percent/100)\n",
    "        ax[i//2, i%2].set_ylim(0, 0.2)\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a window of around size 10 gives good results. <br />\n",
    "At this stage it's clear that there are 3 modes of operation: *normal, faulty*, and *failed*. <br /> \n",
    "These seem to be characterized as follows:\n",
    "* Normal mode: oscillatory with constant frequency and amplitude\n",
    "* Faulty mode: oscillatory, but with highly varying amplitude/frequency\n",
    "* Failed mode: near zero signal\n",
    "\n",
    "<br />\n",
    "Now, we need to build a model that can tell us the operating mode of the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we see from the spectrogram that the signal is almost \"monochromatic\" in the normal mode of operation. <br />\n",
    "\n",
    "We might expect that the machine starts out in the normal state, so one of the simplest things to do would be to calculate how \"far\" the spectrogram is from the initial stages of operation. We can set a threshold for the error or distance from the inital state, beyond which we say the system is in the faulty/failed state. <br />\n",
    "\n",
    "Before we do that, let's rescale all the amplitudes so that for each sensor, amplitudes are relative to the maximum intial amplitude for that sensor. We want to do this because different sensors have different scales for the signal. We can simply calculate the L2 norm between the rescaled spectrogram at a certain time and the initial state and use this as the metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to calculate spectrogram and rescale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_data(data:pd.DataFrame, segment_length=64)->pd.DataFrame:\n",
    "    \n",
    "    spectra = []\n",
    "\n",
    "    for sensor in data.columns:\n",
    "        #calculate the spectrogram for each sensor and add it to a dataframe\n",
    "        f, t, Sxx = signal.spectrogram(data[sensor], nperseg=segment_length)\n",
    "\n",
    "        index = pd.Series(t.astype(int), name=\"time\")\n",
    "        columns = pd.MultiIndex.from_tuples([(sensor, x) for x in f], names=[\"sensor\", \"frequency\"])\n",
    "\n",
    "        spectra.append(pd.DataFrame(Sxx.T, index=index, columns=columns))\n",
    "\n",
    "    return pd.concat(spectra, axis=1)\n",
    "\n",
    "\n",
    "def rescale_spec_data(spec_data:pd.DataFrame)->pd.DataFrame:\n",
    "\n",
    "    rescaled_data = spec_data.copy()\n",
    "\n",
    "    for sensor in spec_data.columns.unique(0):\n",
    "        rescaled_data[sensor] /= (rescaled_data[sensor].iloc[0].max())\n",
    "\n",
    "    return rescaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fae1e45154947c5b5f5321f83649666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_spectrogram_error(machine=(0, 19), percent=(2, 100)):\n",
    "\n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "    clean_data = smooth_data(remove_spikes(data))\n",
    "\n",
    "    rescaled_data = rescale_spec_data(spectrogram_data(clean_data))\n",
    "\n",
    "    X = rescaled_data.values\n",
    "    plt.plot(rescaled_data.index, np.linalg.norm(X-X[0], axis=1))\n",
    "    plt.xlim(0, rescaled_data.index[-1]*percent/100)\n",
    "    plt.ylim(0)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Error relative to initial state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through these, we see that a threshold of 1 would work well. In most cases, this is also half the error between the inital and failure state. Here is the full pipeline with this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faults(data, window=10, segment_length=64, threshold=1):\n",
    "    \n",
    "    # a function that returns the times of the detected faults\n",
    "\n",
    "    clean_data = smooth_data(remove_spikes(data), window=window)\n",
    "    spec_data = spectrogram_data(clean_data, segment_length=segment_length)\n",
    "    rescaled_data = rescale_spec_data(spec_data)\n",
    "    error = np.linalg.norm(rescaled_data-rescaled_data.iloc[0], axis=1)\n",
    "\n",
    "    return list(rescaled_data.index[error > threshold])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the modes of operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efa593cd6fe4226b2998a377ef280b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data_with_faults(machine=(0,19),percent=(2,100)):\n",
    "\n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "\n",
    "    faults = detect_faults(data)\n",
    "    if faults:\n",
    "        time = min(faults)\n",
    "    else:\n",
    "        time=len(data)\n",
    "\n",
    "    clean_data = smooth_data(remove_spikes((data)))\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    \n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i//2, i%2].plot(range(time), clean_data.iloc[:int(time)][str(i)])\n",
    "        ax[i//2, i%2].plot(range(time, len(data)), clean_data.iloc[int(time):][str(i)])\n",
    "\n",
    "        # ax[i//2, i%2].plot(range(len(data)), clean_data[str(i)])\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach seems to work quite well for all the machines we have! <br />\n",
    "The major drawback of this approach is that it is quite specific to the fact that the normal state of these machines has this particular oscillatory behavior. <br />\n",
    "A more generic approach would be as follows: \n",
    "* Assume all machines of a similar kind have a similar normal state and that we have data for these\n",
    "* Assume that for some initial window of time all these machines operate in the normal state\n",
    "* Train a model that predicts either the future states (assuming they are on normal mode) or reconstructs the present state\n",
    "* Measure the error between this predition/reconstruction and the actual values\n",
    "* If this crosses a threshold we have a faulty/broken machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a sliding window of some fixed size and use the sensor data in that window to predict some future readings. If the model is only trained for the normal mode of operation we might expect that the model performs badly in the other modes of operation. First let's create a dataset that has the features and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_regression_data(data, start=10, end=110, step=10, pred_size=2):\n",
    "\n",
    "    clean_data = smooth_data(remove_spikes(data), start)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(start, (end//step)*step):\n",
    "        X.append(clean_data.values[i : i+step].flatten())\n",
    "        y.append(clean_data.values[i+step : i+step+pred_size].flatten())\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional models: Linear/random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stick to machine 0  for now. First we establish a baseline MSE by simply predicting the last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE:  8.016965736892532\n"
     ]
    }
   ],
   "source": [
    "start, end, step, pred_size = 10, 110, 10, 2\n",
    "\n",
    "data = pd.read_csv(\"data/machine_0.csv\", index_col=0)\n",
    "X, y = process_regression_data(data, start, end, step, pred_size)\n",
    "\n",
    "y_pred = np.tile(X[:, -4:], pred_size)\n",
    "\n",
    "print(\"Baseline MSE: \", mean_squared_error(y, y_pred)/pred_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can improve the baseline MSE by building a simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model MSE:  0.05683105403894098\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LinearRegression())\n",
    "\n",
    "pipe.fit(X, y)\n",
    "\n",
    "y_pred = pipe.predict(X)\n",
    "\n",
    "print(\"Linear model MSE: \", mean_squared_error(y, y_pred)/pred_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a massive improvement in the MSE. Now let's generate predictions for the rest of the time series to see how we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f091438be5424ca29b8c60e7ed514bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=51, description='percent', min=2), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test, y_test = process_regression_data(data, start=start, end=2900, step=step, pred_size=pred_size)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "@interact\n",
    "def plot_linear_model(percent=(2,100)):\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i//2, i%2].plot(range(start, start+len(y_pred)), y_test[:, i], ls='', marker='o', ms=2, label=\"actual\")\n",
    "        ax[i//2, i%2].plot(range(start, start+len(y_pred)), y_pred[:, i], ls='--', label=\"predicted\")\n",
    "        ax[i//2, i%2].set_xlim(0, len(y_pred)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we do quite well in the normal mode, but not so, in the faulty mode. We can once again set a threshold for the error to find where the faulty behavior occurs. Here is the whole thing for every machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faults_regression(data, model, threshold=10, **kwargs):\n",
    "    #Function to detect faults using regression\n",
    "\n",
    "    #process regression data (include smoothing)\n",
    "    X_train, y_train = process_regression_data(data, **kwargs)\n",
    "\n",
    "    kwargs['end'] = 2900\n",
    "    X_test, y_test = process_regression_data(data, **kwargs)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    pred_length = kwargs.get(\"pred_length\", 2)\n",
    "    errors = np.average((y_pred-y_test)**2, axis=1)/pred_length\n",
    "\n",
    "    start = kwargs.get(\"start\", 10)\n",
    "    ind = np.arange(start, kwargs[\"end\"])[errors > threshold]\n",
    "\n",
    "    if len(ind)==0:\n",
    "        time = len(data)\n",
    "    else:\n",
    "        time = start+ind[0]\n",
    "\n",
    "    return time\n",
    "\n",
    "\n",
    "\n",
    "def plot_faults(data, time, percent=50):\n",
    "    #Plot the data where time is the earliest detected fault\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    \n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i//2, i%2].plot(range(time), data.iloc[:int(time)][str(i)])\n",
    "        ax[i//2, i%2].plot(range(time, len(data)), data.iloc[int(time):][str(i)])\n",
    "\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0df70b31da4142a23a1c88ecfd2a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def linear_model(machine=(0, 19), percent=(2, 100)):\n",
    "\n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "    clean_data = smooth_data(remove_spikes(data))\n",
    "\n",
    "    time = detect_faults_regression(data, LinearRegression())\n",
    "\n",
    "    plot_faults(clean_data, time, percent)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222839455c0a42678b7f70251aa15a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def linear_model(machine=(0, 19), percent=(2, 100)):\n",
    "\n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "    clean_data = smooth_data(remove_spikes(data))\n",
    "\n",
    "    time = detect_faults_regression(data, RandomForestRegressor(), threshold=20)\n",
    "\n",
    "    plot_faults(clean_data, time, percent)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1673871403615263"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('dschallenge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "efb659ecea875016f1b547ddbdaba28296749251aec33800fbd098c8a825d334"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
