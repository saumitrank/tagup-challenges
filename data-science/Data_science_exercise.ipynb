{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagup Data Science Exercise\n",
    "\n",
    "ExampleCo, Inc is gathering several types of data for its fleet of very expensive machines.  These very expensive machines have three operating modes: *normal*, *faulty* and *failed*.   The machines run all the time, and usually they are in normal mode.  However, in the event that the machine enters faulty mode, the company would like to be aware of this as soon as possible.  This way they can take preventative action to avoid entering failed mode and hopefully save themselves lots of money.\n",
    "\n",
    "They collect four kinds of timeseries data for each machine in their fleet of very expensive machines.  When a machine is operating in *normal* mode the data behaves in a fairly predictable way, but with a moderate amount of noise.  Before a machine fails it will ramp into *faulty* mode, during which the data appears visibly quite different.  Finally, when a machine fails it enters a third, and distinctly different, *failed* mode where all signals are very close to 0.\n",
    "\n",
    "You can download the data here: [exampleco_data](https://drive.google.com/open?id=1b12u6rzkG1AxB6wLGl7IBVoaoSoZLHNR)\n",
    "\n",
    "## Objectives \n",
    "\n",
    "1. **Your primary objective is to develop an approach to detect the beginning of the “faulty” period**. Ideally, this approach would give the ExampleCo engineers as much time as possible to shut down their machines before failure occurs (at which time all measurements drop close to 0). The best solutions are automated in the sense that they would generalize to similar but slightly different data; simpler methods are acceptable but are less likely to receive full credit.\n",
    "2. Demonstrate the efficacy of your approach using visualizations. You must also include a simple explanation of these figures and why your approach is effective, ideally written in language that non-technical executives could understand.\n",
    "3. Finally, and now with a technical audience in mind, discuss the strengths and limitations of your approach and be sure to mention other approaches that you would have liked to try if you had more time.\n",
    "\n",
    "\n",
    "## Notes to help\n",
    "1. A good place to start is by addressing the noise due to communication\n",
    "   errors.\n",
    "2. Feel free to use any libraries you like. Your final results should be\n",
    "   presented in this Python notebook.\n",
    "3. There are no constraints on the techniques you bring to bear, we are curious\n",
    "   to see how you think and what sort of resources you have in your toolbox.\n",
    "4. **Be sure to clearly articulate what you did, why you did it, and how the\n",
    "   results should be interpreted**. In particular, you should be aware of the\n",
    "   limitations of whatever approach or approaches you take.\n",
    "5. Don't feel compelled to use all the data if you're not sure how. Feel free\n",
    "   to focus on data from a single unit if that makes it easier to get started.\n",
    "6. Don't hesitate to reach out to datasciencejobs@tagup.io with any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from scipy import signal\n",
    "from ipywidgets import interact\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with an EDA of all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4e09243cbc465390c6fc538e4d9058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data(machine=(0,19),percent=(2,100)):\n",
    "    \n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        \n",
    "        ax[i//2, i%2].plot(range(len(data)), data[str(i)])\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrolling through all the machines, we see that there are massive spikes due to the communications errors that mask out the signal. We need to remove these first. Since all the spikes occur over a value of 100, we can simply remove these values and replace them with a linear interpolation of the neighboring values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spikes(data):\n",
    "\n",
    "    cutoff = 100\n",
    "    data[abs(data)>cutoff] = np.nan\n",
    "    data = data.interpolate()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971b7bc9bb6d4f8ab0f4fa57ef28d3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data(machine=(0,19),percent=(2,100)):\n",
    "    \n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        \n",
    "        ax[i//2, i%2].plot(range(len(data)), remove_spikes(data[str(i)]))\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot only around 2% of the data, we see that the signals from most sensors and machines are generally oscillatory, but there is also a high frequency component to the signals we might want to smooth over. Let's do this by simply taking a moving average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(data, window=10):\n",
    "    return data.rolling(window=window, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa608c7d52e54425a46cbf560c6becfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data(machine=(0,19),percent=(2,100)):\n",
    "    \n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "    clean_data = smooth_data(remove_spikes(data))\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "            \n",
    "        ax[i//2, i%2].plot(range(len(data)), clean_data[str(i)])\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better. <br />\n",
    "At this stage it's clear that there are 3 modes of operation: *normal, faulty*, and *failed*. <br /> \n",
    "These seem to be characterized as follows:\n",
    "* Normal mode: oscillatory with constant frequency and amplitude\n",
    "* Faulty mode: oscillatory, but with highly varying amplitude/frequency\n",
    "* Failed mode: near zero signal\n",
    "\n",
    "<br />\n",
    "Now, we need to build a model that can tell us the operating mode of the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approack 1: Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have labelled data, we need to use some form of unsupervised learning. <br />\n",
    "One option is to take batches of the data and see how they relate to each other. Given the nature of the data, we care about variations in frequency and aplitude over time. This suggests that a spectrogram would be a good representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a9b9747154dac8d99f640a0fa1d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_spectrogram(machine=(0, 19), percent=(2, 100), segment_size=[16, 32, 64, 128, 256]):\n",
    "\n",
    "    data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "    clean_data = smooth_data(remove_spikes(data))\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        f, t, Sxx = signal.spectrogram(clean_data[str(i)], nperseg=segment_size)\n",
    "\n",
    "        ax[i//2, i%2].pcolormesh(t, f, Sxx, shading='nearest', cmap=\"coolwarm\")\n",
    "        ax[i//2, i%2].set_ylabel('Frequency')\n",
    "        ax[i//2, i%2].set_xlabel('Time')\n",
    "        ax[i//2, i%2].set_xlim(0, t[-1]*percent/100)\n",
    "        ax[i//2, i%2].set_ylim(0, 0.2)\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00.000000000</th>\n",
       "      <td>12.626096</td>\n",
       "      <td>8.803120</td>\n",
       "      <td>-11.809200</td>\n",
       "      <td>10.083961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 08:00:09.603201067</th>\n",
       "      <td>10.831994</td>\n",
       "      <td>2.816327</td>\n",
       "      <td>11.554778</td>\n",
       "      <td>21.892853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:00:19.206402134</th>\n",
       "      <td>21.083510</td>\n",
       "      <td>-0.672645</td>\n",
       "      <td>-17.839178</td>\n",
       "      <td>-1.349024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:28.809603201</th>\n",
       "      <td>32.294495</td>\n",
       "      <td>6.525132</td>\n",
       "      <td>-13.498586</td>\n",
       "      <td>-4.250752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 08:00:38.412804268</th>\n",
       "      <td>28.057100</td>\n",
       "      <td>3.691359</td>\n",
       "      <td>21.984744</td>\n",
       "      <td>13.670561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0         1          2          3\n",
       "2019-01-01 00:00:00.000000000  12.626096  8.803120 -11.809200  10.083961\n",
       "2019-01-01 08:00:09.603201067  10.831994  2.816327  11.554778  21.892853\n",
       "2019-01-01 16:00:19.206402134  21.083510 -0.672645 -17.839178  -1.349024\n",
       "2019-01-02 00:00:28.809603201  32.294495  6.525132 -13.498586  -4.250752\n",
       "2019-01-02 08:00:38.412804268  28.057100  3.691359  21.984744  13.670561"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/machine_0.csv',index_col=0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected there are 4 time-series data from sensors that appear to be taken at 8 hour intervals (based on the index of the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.816016</td>\n",
       "      <td>-1.091308</td>\n",
       "      <td>1.267945</td>\n",
       "      <td>0.165844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>58.078319</td>\n",
       "      <td>55.965665</td>\n",
       "      <td>56.538700</td>\n",
       "      <td>56.910659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-323.954437</td>\n",
       "      <td>-258.780879</td>\n",
       "      <td>-287.153920</td>\n",
       "      <td>-365.362164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.008684</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>-0.008274</td>\n",
       "      <td>-0.007883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000402</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.008685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>315.738951</td>\n",
       "      <td>264.374782</td>\n",
       "      <td>281.684102</td>\n",
       "      <td>340.513819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000\n",
       "mean     -0.816016    -1.091308     1.267945     0.165844\n",
       "std      58.078319    55.965665    56.538700    56.910659\n",
       "min    -323.954437  -258.780879  -287.153920  -365.362164\n",
       "25%      -0.008684    -0.008851    -0.008274    -0.007883\n",
       "50%      -0.000402    -0.000085     0.000669     0.000310\n",
       "75%       0.007832     0.008373     0.009056     0.008685\n",
       "max     315.738951   264.374782   281.684102   340.513819"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3000 data points for this particular machine and no missing values. Now let's visualize this for each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d89287dce344e7bec13944684875de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n', max=3), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_sensor_data(n=(0,3)):\n",
    "    sensor = str(n)\n",
    "    plt.plot(range(len(data)), data[sensor])\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Sensor value')\n",
    "    plt.title('Sensor '+sensor)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the data is quite spiky for all the sensors. This is probably due to the communications errors mentioned in the beginning. Let's try to deal with this first. We can start with a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da4163a88034316be41c58a501859d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='sensor', max=3), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_sensor_data_histogram(sensor=(0,3)):\n",
    "    plt.hist(data[str(sensor)], bins=50)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Sensor value')\n",
    "    plt.title('Sensor '+str(sensor))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the spike values are rare and much larger in magnitude than the actual data. The spike values are also quite symmetric. Let's dig deeper with a CDF plot of the absolute sensor value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7969c2af414b4fa7a7f101694865e2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='sensor', max=3), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_sensor_data_cdf_diff(sensor=(0,3)):\n",
    "\n",
    "    #get histogram, cdf, and \"derivative\"\n",
    "    counts, bins = np.histogram(abs(data[str(sensor)]), bins=50)\n",
    "    cdf = np.cumsum(counts)/len(data)\n",
    "    values = (bins[:-1]+bins[1:])/2\n",
    "    diff = cdf[1:]-cdf[:-1]\n",
    "    ind = np.argmax(diff)\n",
    "\n",
    "    #plot\n",
    "    plt.plot(values, cdf)\n",
    "    plt.plot(values[ind], cdf[ind], \"ro\")\n",
    "    plt.ylabel('CDF')\n",
    "    plt.xlabel('Sensor value magnitude')\n",
    "    plt.title('Sensor '+str(sensor))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the outlier values can be identified by finding the maximum of the CDF derivative, as shown by the red dot. Note that they always seem to occur around 95th percentile. We can now get rid of the outlier values and replace them with a linear itnerpolation of the nearby values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c70b42ed6fc408ea9ae29d7c1c2de07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='sensor', max=3), IntSlider(value=51, description='percen…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_sensor_data_remove_spikes(sensor=(0,3), percent=(2, 100)):\n",
    "\n",
    "    #get histogram, cdf, and \"derivative\"\n",
    "    y = data[str(sensor)].copy()\n",
    "    counts, bins = np.histogram(abs(y), bins=50)\n",
    "    cdf = np.cumsum(counts)/len(data)\n",
    "    diff = cdf[1:]-cdf[:-1]\n",
    "    ind = np.argmax(diff)\n",
    "    cutoff = ((bins[:-1]+bins[1:])/2)[ind-1]\n",
    "\n",
    "    # replace outlier values with nan\n",
    "    cond = (abs(y) > cutoff)\n",
    "    y[cond] = np.nan\n",
    "\n",
    "    #plot\n",
    "    plt.plot(range(len(y)), y.interpolate())\n",
    "    plt.xlim(0, len(y)*percent/100)\n",
    "    plt.ylabel('CDF')\n",
    "    plt.ylabel('Sensor value')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.title('Sensor '+str(sensor))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better. Now let's remove the additional high frequency noise by taking a moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc968e5c59da4b02b5721a522ba07741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=51, description='percent', min=2), IntSlider(value=10, description='wind…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data_clean(percent=(2, 100), window=(1, 20)):\n",
    "\n",
    "    #process data using the function denoise_data defined in utils.py\n",
    "    clean_data = utils.denoise_data(data, window)\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i//2, i%2].plot(range(len(data)), clean_data[str(i)])\n",
    "        ax[i//2, i%2].set_xlim(0, len(data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a window of around size 10 gives good results. <br />\n",
    "At this stage it's clear that there are 3 modes of operation: *normal, faulty*, and *failed*. <br /> \n",
    "These seem to be characterized as follows:\n",
    "* Normal mode: oscillatory with constant frequency and amplitude\n",
    "* Faulty mode: oscillatory, but with highly varying amplitude/frequency\n",
    "* Failed mode: near zero signal\n",
    "\n",
    "<br />\n",
    "Now, we need to build a model that can tell us the operating mode of the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have labelled data, we need to use some form of unsupervised learning. <br />\n",
    "One option is to take batches of the data and see how they relate to each other. Given the nature of the data we care about variations in frequency and aplitude over time. This suggests that a spectrogram would be a good representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead693e9e5e84604a61e5742d78a233a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=51, description='percent', min=2), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_data = utils.denoise_data(data, window=10)\n",
    "\n",
    "@interact\n",
    "def plot_spectrogram(percent=(2, 100)):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    for i in range(4):\n",
    "        f, t, Sxx = signal.spectrogram(clean_data[str(i)], nperseg=64)\n",
    "\n",
    "        ax[i//2, i%2].pcolormesh(t, f, Sxx, shading='nearest', cmap=\"coolwarm\")\n",
    "        ax[i//2, i%2].set_ylabel('Frequency')\n",
    "        ax[i//2, i%2].set_xlabel('Time')\n",
    "        ax[i//2, i%2].set_xlim(0, t[-1]*percent/100)\n",
    "        ax[i//2, i%2].set_ylim(0, 0.2)\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we see from the spectrogram that the signal is almost \"monochromatic\" in the normal mode. Let's rescale all the amplitudes so that for each sensor, amplitudes are relative to the maximum intial amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data = utils.spectrogram_data(clean_data)\n",
    "\n",
    "rescaled_data = utils.rescale_spec_data(spec_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might expect that the machine starts out in the normal state, so one of the simplest things to do would be to calculate how \"far\" the spectrogram is from the initial stages of operation. We can set a threshold for the error or distance from the inital state, beyond which we say the system is in the faulty faulty/failed state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99128a3a2edc4999be00938cc9c49301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=51, description='percent', min=2), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_spectrogram_error(percent=(2, 100)):\n",
    "    X = rescaled_data.values\n",
    "    plt.plot(rescaled_data.index, np.linalg.norm(X-X[0], axis=1))\n",
    "    plt.xlim(0, rescaled_data.index[-1]*percent/100)\n",
    "    plt.ylim(0)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Error relative to initial state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this machine, it seems that an error of 1 is a good threshold. Now let's see if this approach generalizes to other machines. If the other other machines operate in a similar way, i.e the normal state is oscillatory with a similar freq and amplitude, we should be okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does this genralize to another machine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the full \"pipeline\" with some hyperparameters that can be tuned to a specific machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_data(data:pd.DataFrame, nperseg=64)->pd.DataFrame:\n",
    "    \n",
    "    spectra = []\n",
    "\n",
    "    for sensor in data.columns:\n",
    "        \n",
    "        f, t, Sxx = signal.spectrogram(data[sensor], nperseg=nperseg)\n",
    "\n",
    "        index = pd.Series(t.astype(int), name=\"time\")\n",
    "        columns = pd.MultiIndex.from_tuples([(sensor, x) for x in f], names=[\"sensor\", \"frequency\"])\n",
    "\n",
    "        spectra.append(pd.DataFrame(Sxx.T, index=index, columns=columns))\n",
    "\n",
    "    return pd.concat(spectra, axis=1)\n",
    "\n",
    "def rescale_spec_data(spec_data):\n",
    "\n",
    "    rescaled_data = spec_data.copy()\n",
    "\n",
    "    for sensor in spec_data.columns.unique(0):\n",
    "        rescaled_data[sensor] /= (rescaled_data[sensor].iloc[0].max())\n",
    "\n",
    "    return rescaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faults(data, window=10, nperseg=64, threshold=1):\n",
    "    \n",
    "    # a function that returns the times of the detected faults\n",
    "\n",
    "    clean_data = smooth_data(remove_spikes(data), window=window)\n",
    "    spec_data = spectrogram_data(clean_data, nperseg=nperseg)\n",
    "    rescaled_data = rescale_spec_data(spec_data)\n",
    "    error = np.linalg.norm(rescaled_data-rescaled_data.iloc[0], axis=1)\n",
    "\n",
    "    return list(rescaled_data.index[error > threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_faults(pd.read_csv(\"data/machine_0.csv\", index_col=0), nperseg=64)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8766d7dbd4cd49969103e88476ac24a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=9, description='machine', max=19), IntSlider(value=51, description='perc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_data_with_faults(machine=(0,19),percent=(2,100)):\n",
    "\n",
    "    new_data = pd.read_csv(\"data/machine_\"+str(machine)+\".csv\", index_col=0)\n",
    "\n",
    "    faults = detect_faults(new_data)\n",
    "    if faults:\n",
    "        time = min(faults)\n",
    "    else:\n",
    "        time=len(data)\n",
    "\n",
    "    clean_data = smooth_data(remove_spikes((new_data)))\n",
    "\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    \n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i//2, i%2].plot(range(time), clean_data.iloc[:int(time)][str(i)])\n",
    "        ax[i//2, i%2].plot(range(time, len(new_data)), clean_data.iloc[int(time):][str(i)])\n",
    "\n",
    "        # ax[i//2, i%2].plot(range(len(data)), clean_data[str(i)])\n",
    "        ax[i//2, i%2].set_xlim(0, len(new_data)*percent/100)\n",
    "        ax[i//2, i%2].set_xlabel('Time step')\n",
    "        ax[i//2, i%2].set_title('Sensor '+str(i))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach seems to work well for very few of the machines. Browsing through"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('dschallenge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "efb659ecea875016f1b547ddbdaba28296749251aec33800fbd098c8a825d334"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
